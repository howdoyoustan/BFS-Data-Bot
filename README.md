# BFS-Data-Bot
Agentic Solution to debug Data Engineering Errors

This is the Reference Architecture for your BFS Data Debugging Agent. It integrates the Self-Learning Knowledge Base, Airflow Observability, and SQL Investigation into a unified LangGraph application, wrapped in strict banking compliance layers.
1. System Architecture Diagram
The system is divided into three zones: The Secure Zone (User/Orchestrator), The Execution Zone (Tools), and The Data Zone (Infrastructure).
A. The Core Components
The Orchestrator (LangGraph): The central state machine. It does not "think" about data; it thinks about process (Routing, State Management).
The Brain (GPT-4o via Azure OpenAI): Provides reasoning. Critically, it is isolated inside a Private VNET to ensure no data leaks to the public internet.
The Memory (ChromaDB/Pinecone): Stores the Knowledge Base (Docs, Scripts, Historical Fixes).
2. The Graph Design (State Machine)
We utilize a Supervisor-Worker topology with a Feedback Loop.
The State Schema
This is the "packet" of information passed between nodes.
Python

class AgentState(TypedDict):
    # Chat History
    messages: Annotated[List[BaseMessage], add_messages]
    
    # Context Slots
    user_intent: str             # 'LIVE_DEBUG', 'KNOWLEDGE_SEARCH', 'AIRFLOW_CHECK'
    sql_results: Optional[str]   # Result of SQL Query
    log_snippet: Optional[str]   # Result of Airflow Log Fetch
    
    # The Learning Loop
    retrieved_docs: List[Document]
    generated_solution: str      # The fix generated by LLM if Docs were empty
    ready_to_learn: bool         # Flag to trigger the Harvester Node


The Nodes (Workflow)
Supervisor Node:
Input: User Query.
Logic: Classifies intent.
Routes:
"My report is empty" $\rightarrow$ SQL Investigator
"My DAG failed" $\rightarrow$ Airflow Inspector
"How do I install X?" or "Error 127" $\rightarrow$ Knowledge Manager
SQL Investigator Node:
Generates SELECT statements.
Executes via Read-Only Service Account.
Output: Returns row counts/null checks.
Airflow Inspector Node:
Identifies DAG ID from context.
Hits Airflow API (/dagRuns, /taskInstances/logs).
Output: Returns parsed error logs (e.g., "Timeout", "KeyError").
Knowledge Manager Node (The Self-Learner):
Step 1 (Read): Queries Vector DB. High confidence match? Return answer.
Step 2 (Solve): No match? Ask LLM to solve based on first principles.
Step 3 (Write/Harvest): If LLM solves it, tag state as ready_to_learn = True.
Harvester Node (The Writer):
Trigger: Only runs if ready_to_learn is True.
Action: Sanitizes the generated_solution, formats it as a Q&A pair, and upserts it into Vector DB with metadata {'verified': False}.
3. Critical BFS Guardrails (The Security Layer)
In Banking, "Functionality" is secondary to "Security." Here is how you enforce compliance.
I. The "Air Gap" for Data (PII Sanitization)
The LLM must never see raw customer data.
Ingress Guard (Input):
Before the user query hits the Supervisor, run regex to mask Account Numbers, SSNs, and Credit Card numbers.
Regex: \b\d{4}-\d{4}-\d{4}-\d{4}\b $\rightarrow$ [CARD_NUM]
Egress Guard (SQL Output):
The SQL Agent must execute queries, fetch the DataFrame, and run a PII Scrubber (using Microsoft Presidio or pure Python regex) before converting the DataFrame to string and passing it to the LLM.
II. Read-Only Enforcement
Database: The connection string used by the SQL Investigator must belong to a database user with GRANT SELECT ON SCHEMA x only. All INSERT, UPDATE, DELETE, DROP permissions must be revoked at the database level.
Prompt Injection Defense: Even if the LLM is tricked into outputting DROP TABLE, the database driver will throw a permission error.
III. The "Quarantine" Strategy for Knowledge
To prevent Data Poisoning (where the AI learns bad habits):
Tagging: All auto-generated knowledge entries are tagged status: unverified.
Disclaimer: When the agent retrieves an unverified answer, it prefaces the response: "Note: This solution was auto-generated from a previous session and has not been reviewed by a human."
The "Golden Record" Dashboard: Build a simple UI (Streamlit Admin Page) where a Senior Engineer can review unverified entries once a week and click "Approve" (changing metadata to verified: true).
4. Detailed Data Flow Sequence
Scenario: A New Error Encountered (The Learning Loop)
User: "I'm getting Error: Java Heap Space when running the ingestion script."
Supervisor: Routes to Knowledge Manager.
Knowledge Manager:
Queries Vector DB. Result: No Match.
Prompts LLM: "Act as a Java Expert. Fix Java Heap Space in a Spark context."
LLM Generates: "You need to increase -Xmx or spark.driver.memory."
Action: Sets generated_solution = "Increase spark.driver.memory", Sets ready_to_learn = True.
Harvester Node:
Checks generated_solution for PII (None found).
Upserts to Vector DB:
Content: "Issue: Java Heap Space... Fix: Increase spark memory..."
Meta: {'source': 'auto-gen', 'verified': False}
Agent Response: "I didn't find this in our docs, but I suggest increasing your spark memory settings. I have added this to my knowledge base."



5. Technology Stack Summary
Component
Technology
Role
Orchestration
LangGraph
Managing state, loops, and conditional routing.
LLM
Azure OpenAI (GPT-4o)
Reasoning and Code Generation (Private Instance).
Vector Store
ChromaDB (or Faiss)
Storing Knowledge Base and Scripts.
SQL Engine
SQLAlchemy
Generic connector for Snowflake/Oracle/Postgres.
Observability
Apache Airflow Client
REST API interaction for logs.
Frontend
Streamlit
User Interface for Chat + Admin Verification Panel.
Security
Microsoft Presidio
PII Entities identification and redaction.


